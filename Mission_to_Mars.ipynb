{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "from bs4 import BeautifulSoup\n",
    "from splinter import Browser\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "import selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Windows\n",
    "# Set Executable Path & Initialize Chrome Browser\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For MAC\n",
    "# Set Executable Path & Initialize Chrome Browser\n",
    "#executable_path = {\"executable_path\": \"/usr/local/bin/chromedriver\"}\n",
    "#browser = Browser(\"chrome\", **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NASA news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Scrape the NASA Mars News Site and collect the latest News Title and Paragraph Text. Assign the text to variables that you can reference later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Access and visit the NASA Mars News Site URL\n",
    "news_url = 'https://mars.nasa.gov/news/'\n",
    "browser.visit(news_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "NASA's Perseverance Rover Begins Its First Science Campaign on Mars\n",
      "The six-wheeled scientist is heading south to explore Jezero Craterâ€™s lakebed in search of signs of ancient microbial life.\n"
     ]
    }
   ],
   "source": [
    "# HTML object\n",
    "html = browser.html\n",
    "\n",
    "# Parse HTML with BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Retrieve all elements that contain news title\n",
    "latest_news = soup.find_all('div', class_=\"list_text\")\n",
    "\n",
    "# Get the latest news    \n",
    "news = latest_news[0]\n",
    "\n",
    "# Use BeautifulSoup'find() method to navigate and retrieve attributes\n",
    "news_title = news.find('div', class_='content_title').text\n",
    "news_p = news.find('div', class_='article_teaser_body').text\n",
    "\n",
    "# display information\n",
    "print('------------')\n",
    "print(news_title)\n",
    "print(news_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JPL Mars Space Images - Featured Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the NASA JPL (Jet Propulsion Laboratory) Site\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path)\n",
    "url = 'https://spaceimages-mars.com/#'\n",
    "browser.visit(news_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit the JPL Featured Space Image website \n",
    "JPLimage_url = 'https://spaceimages-mars.com/#'\n",
    "browser.visit(JPLimage_url)\n",
    "time.sleep(2)\n",
    "\n",
    "# create HTML object\n",
    "html = browser.html\n",
    "\n",
    "#parse HTML with BeautifulSoup \n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<splinter.element_list.ElementList at 0x1cabf0726a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Click through to find full image\n",
    "browser.links.find_by_partial_text('FULL IMAGE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<splinter.element_list.ElementList at 0x1cabf2bc048>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Click again for full large image\n",
    "time.sleep(2)\n",
    "browser.links.find_by_partial_text('more info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-bdd2a3194ff8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Search for image source\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'figure'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lede'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mrelative_img_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mfeatured_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://www.jpl.nasa.gov'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrelative_img_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Search for image source\n",
    "results = soup.find_all('figure', class_='lede')\n",
    "relative_img_path = results[0].a['href']\n",
    "featured_img = 'https://www.jpl.nasa.gov' + relative_img_path\n",
    "\n",
    "print(featured_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- get the <div> with a class of 'carousel_container': this contains the current featured image details ---\n",
    "carousel = soup.find('div', class_='carousel_container')\n",
    "\n",
    "# --- use splinter to click on the 'full image' button to retrieve a full-size jpg url ---\n",
    "full_image_button = browser.find_by_id('full_image')\n",
    "full_image_button.click()\n",
    "time.sleep(1)\n",
    "\n",
    "# --- check if the div with the 'more info' button is visible to proceed to the download page. If false: ---\n",
    "if browser.is_element_visible_by_css('div.fancybox-title') == False:\n",
    "    \n",
    "    # --- create the base url for the image from the carousel container ---\n",
    "    base_url = 'https://www.jpl.nasa.gov/'\n",
    "    \n",
    "    # --- get the image url found under the <a> tag in the carousel ---\n",
    "    image_url = carousel.find('a')['data-fancybox-href']\n",
    "    \n",
    "    # --- complete the featured image url by adding the base url ---\n",
    "    featuredimage_url = base_url + image_url\n",
    "\n",
    "# --- if the div is visible and there is a 'more info' button to proceed --- \n",
    "else:\n",
    "    \n",
    "    # --- create the base url for the fullsize image download link ---\n",
    "    base_url = 'https:'\n",
    "    \n",
    "    # --- click the 'more info' button to go to the image detail page ---\n",
    "    browser.links.find_by_partial_text('more info').click()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # --- create a beautiful soup object with the image detail page's html ---\n",
    "    img_detail_html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # --- find the fullsize jpg image link and store the url ---\n",
    "    download_div = imagesoup.find_all('div', class_='download_tiff')[1]\n",
    "    fullsize_img = download_div.find('a')['href']\n",
    "\n",
    "    # --- complete the featured image url by adding the base url ---\n",
    "    featuredimage_url = base_url + fullsize_img\n",
    "\n",
    "print(featuredimage_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML object\n",
    "img_html = browser.html\n",
    "\n",
    "# Parse HTML with BeautifulSoup\n",
    "soup = BeautifulSoup(img_html, 'html.parser')\n",
    "\n",
    "# STEP 1: click by id = 'full_image' and assign to a variable\n",
    "full_image_elem = browser.links.find_by_partial_text('full_image')\n",
    "full_image_elem\n",
    "\n",
    "# STEP 2: click by text 'more info' and assign to a variable\n",
    "browser.is_element_present_by_text('more info', wait_time=1) # make sure if text in page\n",
    "more_info_elem = browser.links.find_by_partial_text('more info')\n",
    "\n",
    "# use CSS selector in BeautifulSoup to extract img_url\n",
    "image_relative_url = soup.select_one('figure.lede a img').get('src')\n",
    "\n",
    "#combine with base URL to create an absolute img URL\n",
    "img_url = f'https://www.jpl.nasa.gov{image_relative_url}'\n",
    "img_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Save the tweet text for the weather report as a variable called mars_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access and visit Mars Weather twitter URL\n",
    "mars_twitter_url = 'https://twitter.com/marswxreport?lang=en'\n",
    "browser.visit(mars_twitter_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML object\n",
    "twitter_marswx_html = browser.html\n",
    "\n",
    "# Parse HTML with BeautifulSoup\n",
    "soup = BeautifulSoup(twitter_marswx_html, 'html.parser')\n",
    "\n",
    "# Get the text from the latest Mars weather tweet\n",
    "mars_weather = soup.find('p', class_=\"TweetTextSize TweetTextSize--normal js-tweet-text tweet-text\").text\n",
    "\n",
    "# Display the tweet text\n",
    "mars_weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Mars Facts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Table containing facts about the planer.\n",
    "* Convert the data to a HTML table string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access and visit the Mars facts webpage\n",
    "mars_facts_url = 'https://space-facts.com/mars/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get any tabular data from the webpage\n",
    "facts_tables = pd.read_html(mars_facts_url)\n",
    "facts_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datatype of facts_tables\n",
    "type(facts_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice off the dataframe that we want usin normal indexing\n",
    "facts_df = facts_tables[0]\n",
    "facts_df.columns = ['Description', 'Value']\n",
    "\n",
    "# Preview the Dataframe\n",
    "facts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the index to the `Fact` column\n",
    "facts_df.set_index('Description', inplace=True)\n",
    "facts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the Dataframe to HTML\n",
    "html_table = facts_df.to_html()\n",
    "\n",
    "# Preview of the html_table\n",
    "html_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip unwanted newlines to clean up the table\n",
    "html_table.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Access and visit the USGS Astrogeology site\n",
    "mars_hemis_url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "browser.visit(mars_hemis_url)\n",
    "xpath = '//div//a[@class=\"itemLink product-item\"]/img'\n",
    "\n",
    "# Use splinter to Click the image to bring up the full resolution image\n",
    "results = browser.find_by_xpath(xpath)\n",
    "\n",
    "# Initiate hemisphere_image_urls list\n",
    "hemisphere_image_urls = []\n",
    "\n",
    "# Loop over results to get image data\n",
    "for i in range(len(results)):\n",
    "    img = results[i]\n",
    "            \n",
    "    img.click()\n",
    "    \n",
    "    # Scrape the browser into soup and use soup to find the full resolution image of mars\n",
    "    # Save the image url to a variable called `img_url`\n",
    "    mars_usgs_html = browser.html\n",
    "    soup = BeautifulSoup(mars_usgs_html, 'html.parser')\n",
    "    partial_img_url = soup.find(\"img\", class_=\"wide-image\")[\"src\"]\n",
    "    \n",
    "    img_url = 'https://astrogeology.usgs.gov/' + partial_img_url\n",
    "    \n",
    "    # Scrape the browser into soup and use soup to find the title of the image\n",
    "    # Save the image's title to a variable called `img_title`\n",
    "    img_title = soup.find('h2', class_=\"title\").text\n",
    "    \n",
    "    # Get the data into a dictionary\n",
    "    img_dict = {\n",
    "        'img_url': img_url,\n",
    "        'img_title': img_title\n",
    "    }\n",
    "    # Append image dictionaries to the list\n",
    "    hemisphere_image_urls.append(img_dict)\n",
    "\n",
    "    browser.back()\n",
    "    results = browser.find_by_xpath(xpath)\n",
    "    i = i + 1\n",
    "    \n",
    "# Display hemispheres' images list\n",
    "hemisphere_image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nteract": {
   "version": "0.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
